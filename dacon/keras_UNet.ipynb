{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4774a171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "from skimage.util import img_as_ubyte\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ff8314",
   "metadata": {},
   "source": [
    "## UNET 모델링 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6efbc1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### UNet 모델 정의\n",
    "def unet(pretrained_weights = None, input_size=(256,256,1)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2,2))(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2,2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2,2))(conv3)\n",
    "    \n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2,2))(conv4)\n",
    "    \n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "    \n",
    "    up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(conv6)\n",
    "    \n",
    "    up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(conv7)\n",
    "    \n",
    "    up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(conv8)\n",
    "    \n",
    "    up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding ='same', kernel_initializer = 'he_normal')(conv9)\n",
    "    \n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "    \n",
    "    model = Model(input = inputs, output = conv10)\n",
    "    \n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    if(pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a08737",
   "metadata": {},
   "source": [
    "## 데이터 조정에 필요한 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9f9c6cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "\n",
    "Sky = [128,128,128]\n",
    "Building = [128,0,0]\n",
    "Pole = [192,192,128]\n",
    "Road = [128,64,128]\n",
    "Pavement = [60,40,222]\n",
    "Tree = [128,128,0]\n",
    "SignSymbol = [192,128,128]\n",
    "Fence = [64,64,128]\n",
    "Car = [64,0,128]\n",
    "Pedestrian = [64,64,0]\n",
    "Bicyclist = [0,128,192]\n",
    "Unlabelled = [0,0,0]\n",
    "\n",
    "COLOR_DICT = np.array([Sky,Building, Pole, Road, Pavement, Tree, SignSymbol, Fence,\n",
    "                      Car, Pedestrian, Bicyclist, Unlabelled])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2021373",
   "metadata": {},
   "source": [
    "## 데이터 조정 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "94ddb894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjustData(img, mask, flag_multi_class, num_class):\n",
    "    if(flag_multi_class):\n",
    "        img = img / 255\n",
    "        mask = mask[:,:,:,0] if(len(mask.shape)==4) else mask[:,:,0]\n",
    "        new_mask = np.zeros(mask.shape +(num_class,))\n",
    "        for i in range(num_class):\n",
    "            new_mask[mask == i,i] = 1\n",
    "        new_mask = np.reshape(new_mask,(new_mask.shape[0],new_mask.shape[1]*new_mask.shape[2],new_mask.shape[3])) if flas_multi_class else np.reshape(new_mask,(new_mask.shape[0]*new_mask.shape[1],new_mask.shape[2]))\n",
    "        mask = new_mask\n",
    "    elif(np.max(img) > 1):\n",
    "        img = img / 255\n",
    "        mask = mask / 255\n",
    "        mask[mask > 0.5] = 1\n",
    "        mask[mask <= 0.5] = 0\n",
    "    return (img,mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06900cfc",
   "metadata": {},
   "source": [
    "## 학습 데이터로 segmentation 학습을 진행하는 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f518dcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainGenerator(batch_size,train_path,image_folder,mask_folder, aug_dict,image_color_mode = \"grayscale\",\n",
    "                   mask_color_mode = \"grayscale\", image_save_prefix = 'image', mask_save_prefix = 'mask',\n",
    "                   flag_multi_class = False, num_class = 2, save_to_dir = None, target_size = (256,256), seed = 1):\n",
    "    image_datagen = ImageDataGenerator(**aug_dict)\n",
    "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [image_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = image_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix = image_save_prefix,\n",
    "        seed = seed)\n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [mask_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = mask_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix = mask_save_prefix,\n",
    "        seed = seed)\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    for(img,mask) in train_generator:\n",
    "        img,mask = adjustData(img,mask, flag_multi_class,num_class)\n",
    "        yield(img,mask)\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450e6d15",
   "metadata": {},
   "source": [
    "##   테스트 데이터 Segmentation을 진행해 이미지 생성하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "faec92e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testGenerator(test_path,num_image = 20,target_size = (256,256),flag_multi_class = False,as_gray = True):\n",
    "    for i in range(num_image):\n",
    "        img = io.imread(os.path.join(test_path,\"{:03d}.png\".format(i+1)),as_gray = as_gray)\n",
    "        img = img / 255\n",
    "        img = trans.resize(img,target_size)\n",
    "        img = np.reshape(img,img.shape+(1,)) if (not flag_multi_class) else img\n",
    "        img = np.reshape(img,(1,)+img.shape)\n",
    "        yield img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f748e9d",
   "metadata": {},
   "source": [
    "## 레이블 시각화와 결과를 저장하는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3169d7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labelVisualize(num_class,color_dict,img):\n",
    "    img = img[:,:,0] if len(img.shape) == 3 else img\n",
    "    img_out = np.zeros(img.shape + (3,))\n",
    "    for i in range(num_class):\n",
    "        img_out[img == i,:] = color_dict[i]\n",
    "    return img_out / 255\n",
    "\n",
    "\n",
    "\n",
    "def saveResult(save_path,npyfile,flag_multi_class = False,num_class = 2):\n",
    "    for i,item in enumerate(npyfile):\n",
    "        img = labelVisualize(num_class,COLOR_DICT,item) if flag_multi_class else item[:,:,0]\n",
    "        cv2.imwrite(os.path.join(save_path,\"%d_predict.png\"%i),img_as_ubyte(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ece917ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def geneTrainNpy(image_path,mask_path,flag_multi_class = False,num_class = 2,image_prefix = \"image\",mask_prefix = \"mask\",image_as_gray = None,mask_as_gray = True):\n",
    "    image_name_arr = glob.glob(os.path.join(image_path,\"%s*.png\"%image_prefix))\n",
    "    image_arr = []\n",
    "    mask_arr = []\n",
    "    for index,item in enumerate(image_name_arr):\n",
    "        img = io.imread(item, as_gray = image_as_gray)\n",
    "        img = np.reshape(img, img.shape + (1,)) if image_as_gray else img\n",
    "        mask = io.imread(item.replace(image_path,mask_path).replace(image_prefix,mask_prefix),as_gray = mask_as_gray)\n",
    "        mask = np.reshape(mask,mask.shape + (1,)) if mask_as_gray else mask\n",
    "        img,mask = adjustData(img,mask,flag_multi_class,num_class)\n",
    "        image_arr.append(img)\n",
    "        mask_arr.append(mask)\n",
    "    image_arr = np.array(image_arr)\n",
    "    mask_arr = np.array(mask_arr)\n",
    "    return image_arr,mask_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bc1950",
   "metadata": {},
   "source": [
    "## 학습 수행에 필요한 파라미터지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d55623d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_args = dict(rotation_range = 0.2,\n",
    "                    width_shift_range=0.05,\n",
    "                    height_shift_range=0.05,\n",
    "                    shear_range=0.05,\n",
    "                    zoom_range=0.05,\n",
    "                    horizontal_flip=True,\n",
    "                    fill_mode='nearest')\n",
    "myGene = trainGenerator(2,'./data/segmentation', 'train', 'trainannot',data_gen_args, save_to_dir = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1a61dbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_batch = 3\n",
    "# for i,batch in enumerate(myGene):\n",
    "#     if(i >= num_batch):\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8dd733be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_arr,mask_arr = geneTrainNpy(\"data/membrane/train/aug/\",\"data/membrane/train/aug/\")\n",
    "# np.save(\"data/image_arr.npy\",image_arr)\n",
    "# np.save(\"data/mask_arr.npy\",mask_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c2e95167",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/competition/lib/python3.7/site-packages/ipykernel_launcher.py:48: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "Found 99 images belonging to 1 classes.\n",
      "Found 99 images belonging to 1 classes.\n",
      "49/49 [==============================] - 20s 410ms/step - loss: 0.7023 - acc: 0.9781\n",
      "\n",
      "Epoch 00001: loss improved from inf to 0.70233, saving model to keras_Unet.hdf5\n",
      "20/20 [==============================] - 17s 852ms/step\n"
     ]
    }
   ],
   "source": [
    "model = unet()\n",
    "model_checkpoint = ModelCheckpoint('keras_Unet.hdf5', monitor='loss', verbose=1, save_best_only=True)\n",
    "model.fit_generator(myGene, steps_per_epoch= 49, epochs=1,callbacks=[model_checkpoint])\n",
    "\n",
    "testGene = testGenerator('./data/segmentation/test')\n",
    "results = model.predict_generator(testGene,20,verbose=1)\n",
    "saveResult('./data/segmentation/testannot',results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5bc83259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0174157210>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(plt.imread('./data/segmentation/testannot/0_predict.png')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22997a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img2 = cv2.imread('./data/segmentation/aug/mask_31-7109572.png')\n",
    "#img2=np.reshape(img2, img2.shape+(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc650397",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ad7deca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=uint8)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a588503",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:competition] *",
   "language": "python",
   "name": "conda-env-competition-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
